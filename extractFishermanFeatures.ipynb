{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fishermen' from 'C:\\\\Users\\\\dambr\\\\obelix\\\\projets\\\\pytorch\\\\fishermen.py'>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compilation des tests pour simplification\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import glob\n",
    "from os.path import basename\n",
    "import tools as to\n",
    "import fishermen as fi\n",
    "from torch.autograd import Variable\n",
    "from importlib import reload\n",
    "import sys\n",
    "reload(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_folder is : \n",
      "C:/Users/dambr/wipsea/projets/cifre_mathieu/experience/pecheurs/\n",
      "Patches will be stored in output folder : \n",
      "C:/Users/dambr/wipsea/projets/cifre_mathieu/experience/pecheurs/patches/\n",
      "Positive patch ratio per image : 0.5\n",
      "Patch size is : width = 32, height = 64\n"
     ]
    }
   ],
   "source": [
    "0# Chose your input parameters \n",
    "root_folder=\"C:/Users/dambr/wipsea/projets/cifre_mathieu/experience/pecheurs/\"\n",
    "out_folder = root_folder + \"patches/\"\n",
    "posRatio = 0.5\n",
    "patch_width = 32\n",
    "patch_height = 64\n",
    "print(\"root_folder is : \\n\" + root_folder)\n",
    "print(\"Patches will be stored in output folder : \\n\" + out_folder)\n",
    "print(\"Positive patch ratio per image : \" + str(posRatio))\n",
    "print(\"Patch size is : width = %d, height = %d\" % (patch_width, patch_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51619951 0.52364265 0.53038227]\n",
      "[0.05715425 0.05635047 0.05636032]\n",
      "[-0.0007836   0.00055154  0.00176748]\n",
      "[0.99776958 0.99758771 0.99762201]\n"
     ]
    }
   ],
   "source": [
    "fisherman_dataset = fi.FishermanDataset(csv_file=out_folder +'Annotations.csv',\n",
    "                                    root_dir=out_folder, \n",
    "                                       transform=transforms.Compose([\n",
    "                                               fi.Rescale((70,35)),\n",
    "                                               fi.RandomCrop((64,32)),\n",
    "                                               fi.ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "mean, std = fi.calcNorm(fisherman_dataset)\n",
    "print(mean)\n",
    "print(std)\n",
    "fisherman_norm = fi.FishermanDataset(csv_file=out_folder +'Annotations.csv',\n",
    "                                    root_dir=out_folder, \n",
    "                                       transform=transforms.Compose([\n",
    "                                               fi.Rescale((70,35)),\n",
    "                                               fi.RandomCrop((64,32)),\n",
    "                                               fi.ToTensor(),\n",
    "                                               fi.Normalize(tuple(mean),tuple(std))\n",
    "                                           ]))\n",
    "\n",
    "mean, std = fi.calcNorm(fisherman_norm)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51706663 0.52491365 0.53139331]\n",
      "[0.05846014 0.05763357 0.05749327]\n",
      "tensor(-0.1353, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "trainset_unnormalized = fi.FishermanDataset(csv_file=out_folder + \"Annotations.csv\",\n",
    "                                            root_dir=out_folder,\n",
    "                                            transform = fi.ToTensor()\n",
    "                                         )\n",
    "mean, std = fi.calcNorm(trainset_unnormalized)\n",
    "print(mean)\n",
    "print(std)\n",
    "composed_train = transforms.Compose([fi.Rescale((70,35)),\n",
    "                                     fi.RandomCrop((64,32)),\n",
    "                                     fi.ToTensor(),\n",
    "                                     fi.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "                                     ])\n",
    "\n",
    "composed_test = transforms.Compose(\n",
    "    [fi.ToTensor(),\n",
    "     fi.Normalize((0.5,0.5,0.5),(1,1,1))])\n",
    "\n",
    "trainset = fi.FishermanDataset(csv_file=out_folder + \"Annotations.csv\",\n",
    "                                      root_dir=out_folder,\n",
    "                                      transform = composed_train)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=4,\n",
    "                         shuffle=True)\n",
    "\n",
    "testset = fi.FishermanDataset(csv_file=out_folder + \"Annotations_test.csv\",\n",
    "                                      root_dir=out_folder,\n",
    "                                      transform = composed_test)\n",
    "s = testset[2]\n",
    "im = s['image']\n",
    "print(im[2,20,20])\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=1,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params number\n",
      "28429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (line3): Linear(in_features=1344, out_features=20, bias=True)\n",
       "  (line4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (line5): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Create a network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, (3,3))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        self.conv2 = nn.Conv2d(5, 16, (3,3))\n",
    "        self.line3 = nn.Linear(16 * 6 * 14, 20)\n",
    "        self.line4 = nn.Linear(20, 10)\n",
    "        self.line5 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(x.size())\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.size())\n",
    "        x = x.view(-1, 16 * 6 * 14)\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.line3(F.dropout(x,0.1,False,True)))\n",
    "        #print(x.size())\n",
    "        x = F.relu(self.line4(F.dropout(x,0.1,False,True)))\n",
    "        #print(x.size())\n",
    "        x = self.line5(x)\n",
    "        #print(x.size())\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "params = list(net.parameters())\n",
    "print(\"params number\")\n",
    "print(to.get_n_params(net))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 define metaparameter\n",
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.SoftMarginLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 1.395\n",
      "[1,    40] loss: 0.696\n",
      "[1,    60] loss: 0.695\n",
      "[1,    80] loss: 0.696\n",
      "[1,   100] loss: 0.692\n",
      "[1,   120] loss: 0.703\n",
      "[1,   140] loss: 0.676\n",
      "[1,   160] loss: 0.715\n",
      "[1,   180] loss: 0.698\n",
      "[1,   200] loss: 0.703\n",
      "[2,    20] loss: 0.696\n",
      "[2,    40] loss: 0.698\n",
      "[2,    60] loss: 0.696\n",
      "[2,    80] loss: 0.690\n",
      "[2,   100] loss: 0.697\n",
      "[2,   120] loss: 0.692\n",
      "[2,   140] loss: 0.704\n",
      "[2,   160] loss: 0.694\n",
      "[2,   180] loss: 0.695\n",
      "[2,   200] loss: 0.690\n",
      "[3,    20] loss: 0.695\n",
      "[3,    40] loss: 0.696\n",
      "[3,    60] loss: 0.695\n",
      "[3,    80] loss: 0.684\n",
      "[3,   100] loss: 0.724\n",
      "[3,   120] loss: 0.694\n",
      "[3,   140] loss: 0.696\n",
      "[3,   160] loss: 0.694\n",
      "[3,   180] loss: 0.694\n",
      "[3,   200] loss: 0.693\n",
      "[4,    20] loss: 0.693\n",
      "[4,    40] loss: 0.691\n",
      "[4,    60] loss: 0.692\n",
      "[4,    80] loss: 0.694\n",
      "[4,   100] loss: 0.693\n",
      "[4,   120] loss: 0.697\n",
      "[4,   140] loss: 0.698\n",
      "[4,   160] loss: 0.689\n",
      "[4,   180] loss: 0.699\n",
      "[4,   200] loss: 0.697\n",
      "[5,    20] loss: 0.695\n",
      "[5,    40] loss: 0.696\n",
      "[5,    60] loss: 0.694\n",
      "[5,    80] loss: 0.686\n",
      "[5,   100] loss: 0.700\n",
      "[5,   120] loss: 0.695\n",
      "[5,   140] loss: 0.689\n",
      "[5,   160] loss: 0.682\n",
      "[5,   180] loss: 0.697\n",
      "[5,   200] loss: 0.689\n",
      "[6,    20] loss: 0.679\n",
      "[6,    40] loss: 0.671\n",
      "[6,    60] loss: 0.663\n",
      "[6,    80] loss: 0.624\n",
      "[6,   100] loss: 0.639\n",
      "[6,   120] loss: 0.600\n",
      "[6,   140] loss: 0.463\n",
      "[6,   160] loss: 0.299\n",
      "[6,   180] loss: 0.189\n",
      "[6,   200] loss: 0.332\n",
      "[7,    20] loss: 0.376\n",
      "[7,    40] loss: 0.166\n",
      "[7,    60] loss: 0.278\n",
      "[7,    80] loss: 0.141\n",
      "[7,   100] loss: 0.226\n",
      "[7,   120] loss: 0.280\n",
      "[7,   140] loss: 0.307\n",
      "[7,   160] loss: 0.162\n",
      "[7,   180] loss: 0.168\n",
      "[7,   200] loss: 0.254\n",
      "[8,    20] loss: 0.400\n",
      "[8,    40] loss: 0.157\n",
      "[8,    60] loss: 0.168\n",
      "[8,    80] loss: 0.192\n",
      "[8,   100] loss: 0.136\n",
      "[8,   120] loss: 0.120\n",
      "[8,   140] loss: 0.184\n",
      "[8,   160] loss: 0.256\n",
      "[8,   180] loss: 0.150\n",
      "[8,   200] loss: 0.103\n",
      "[9,    20] loss: 0.067\n",
      "[9,    40] loss: 0.083\n",
      "[9,    60] loss: 0.191\n",
      "[9,    80] loss: 0.415\n",
      "[9,   100] loss: 0.254\n",
      "[9,   120] loss: 0.278\n",
      "[9,   140] loss: 0.092\n",
      "[9,   160] loss: 0.154\n",
      "[9,   180] loss: 0.121\n",
      "[9,   200] loss: 0.151\n",
      "[10,    20] loss: 0.163\n",
      "[10,    40] loss: 0.326\n",
      "[10,    60] loss: 0.188\n",
      "[10,    80] loss: 0.117\n",
      "[10,   100] loss: 0.064\n",
      "[10,   120] loss: 0.131\n",
      "[10,   140] loss: 0.134\n",
      "[10,   160] loss: 0.117\n",
      "[10,   180] loss: 0.166\n",
      "[10,   200] loss: 0.074\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "e = 10\n",
    "show = 20\n",
    "to.trainMyNet(net,trainloader,optimizer,criterion,e,show,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 93 test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = to.testMyNet(net,testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Save my net\n",
    "is_best = True\n",
    "to.save_checkpoint({\n",
    "    'epoch': e + 1,\n",
    "    'arch': 'GPU',\n",
    "    'state_dict': net.state_dict(),\n",
    "    'best_prec1': accuracy,\n",
    "    'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (line3): Linear(in_features=1344, out_features=20, bias=True)\n",
       "  (line4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (line5): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "checkpoint = torch.load('C:/Users/dambr/obelix/projets/pytorch/model_best.pth.tar')\n",
    "e = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['best_prec1']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res\n",
      "[ -3.33665633   6.76845598   0.28124112  -3.1149168   -2.33480549\n",
      "  -0.4990955  -12.7186985   -2.47497559   7.57247305  -1.7359612\n",
      "   1.        ]\n"
     ]
    }
   ],
   "source": [
    "reload(fi)\n",
    "test_features = np.ones((1,11))\n",
    "layer = model._modules.get('line4')\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        feat = fi.get_vectors(data, model, layer, device)\n",
    "        f = feat.data[0].numpy()\n",
    "        line = np.zeros((1,11))\n",
    "        line[0,:-1] = f\n",
    "        line[0,10] = float(data['label'].data[0])\n",
    "        test_features = np.append(test_features,line, axis=0)\n",
    "        #test_features.append(line)\n",
    "print(\"Res\")\n",
    "print(test_features[50])\n",
    "df = pd.DataFrame({'f1' : test_features[:,0],\n",
    "                   'f2' : test_features[:,1],\n",
    "                   'f3' : test_features[:,2],\n",
    "                   'f4' : test_features[:,3],\n",
    "                   'f5' : test_features[:,4],\n",
    "                   'f6' : test_features[:,5],\n",
    "                   'f7' : test_features[:,6],\n",
    "                   'f8' : test_features[:,7],\n",
    "                   'f9' : test_features[:,8],\n",
    "                   'f10' : test_features[:,9],\n",
    "                   'label' : test_features[:,10]})\n",
    "df.to_csv(\"test_write.csv\", ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
